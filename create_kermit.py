# -*- coding: utf-8 -*-
"""create_KERMIT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qzvTRIR2jWc4iP-kVTONdfk7hXAOtOaT
"""

import tensorflow as tf

flags = tf.flags

FLAGS = flags.FLAGS

## Required parameters
flags.DEFINE_string(
    "initial_bert", None,
    "Path to file containing a randomly intialized BERT model ")

flags.DEFINE_string(
    "electra_path", None,
    "Path to file containing a trained ELECTRA model")

flags.DEFINE_string(
    "new_checkpoint", None,
    "Path to output file")

def main(_):
  checkpoint_path = FLAGS.electra_path
  new_checkpoint_path = FLAGS.new_checkpoint
  reader = tf.train.NewCheckpointReader(checkpoint_path)
  name_shape_map = reader.get_variable_to_shape_map()

  new_variable_map = {}
  reader_2 = tf.train.NewCheckpointReader(FLAGS.initial_bert)
  name_shape_map_2 = reader_2.get_variable_to_shape_map()
  reader_3 = tf.train.NewCheckpointReader(trained)
  name_shape_3 = reader_3.get_variable_to_shape_map()
  for var_name in name_shape_map:
    if 'electra/encoder' in var_name and 'adam_m' not in var_name and 'adam_v' not in var_name:
          tensor = reader.get_tensor(var_name)
          name = var_name.replace("electra/","bert/")
          print("from electra",name)
          var = tf.Variable(tensor, name=name)
          new_variable_map[name] = var
    if "electra/embeddings" in var_name and 'adam_m' not in var_name and 'adam_v' not in var_name:
          tensor = reader.get_tensor(var_name)
          name = var_name.replace("electra/","bert/")
          print("from electra",name)
          var = tf.Variable(tensor, name=name)
          new_variable_map[name] = var

  for var_name_2 in name_shape_map_2:
    if  'cls' in var_name_2 or 'pooler' in var_name_2 or 'global_step' in var_name_2:
                print("from bert",var_name_2)
                tensor = reader_2.get_tensor(var_name_2)
                var = tf.Variable(tensor, name=var_name_2)
                new_variable_map[var_name_2] = var
  saver = tf.train.Saver(new_variable_map)

  with tf.Session() as sess:
     sess.run(tf.global_variables_initializer())
     saver.save(sess,  new_checkpoint_path,write_meta_graph=False)

if __name__ == "__main__":
  flags.mark_flag_as_required("initial_bert")
  flags.mark_flag_as_required("electra_path")
  flags.mark_flag_as_required("new_checkpoint")
  tf.app.run()